{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"Belgium\"\n",
    "path2SP = \"/Users/ctoruno/OneDrive - World Justice Project/EU Subnational\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import prompt_templates_summarization as pts\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatherFiles(country, p):\n",
    "    \"\"\"\n",
    "    This function takes a country as input and returns a list with all the news articles associated to that specific pillar.\n",
    "    \"\"\"\n",
    "    data_path = f\"{path2SP}/EU-S Data/Automated Qualitative Checks/Data/data-summarization/{country}/pillar_{p}\"\n",
    "    sets = [pd.read_parquet(f\"{data_path}/{x}\") for x in os.listdir(data_path)]\n",
    "    pillar_data = pd.concat(sets)\n",
    "    pillar_data[\"associated_pillar\"] = f\"Pillar {p}\"\n",
    "    print(f\"Pillar {p}: {len(pillar_data)} articles\")\n",
    "\n",
    "    return pillar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pillar 1: 4007 articles\n",
      "Pillar 2: 2341 articles\n",
      "Pillar 3: 583 articles\n",
      "Pillar 4: 2911 articles\n",
      "Pillar 5: 1331 articles\n",
      "Pillar 6: 625 articles\n",
      "Pillar 7: 1695 articles\n",
      "Pillar 8: 3620 articles\n"
     ]
    }
   ],
   "source": [
    "country_data = [gatherFiles(country, p) for p in range(1,9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_system = \"\"\"\n",
    "You are a specialized assistant whose role is to meticulously read and analyze a list of brief news articles and provide a summary of the most important topics related to a specific theme.  I will provide you with further details about the news article summaries and the specific theme that I would like you to focus on. You will have to carefully read the information I will provide to you and identify the most relevant issues or events related to the theme that I will specify. You will have to use your knowledge on politics, law, and social sciences to sucessfully perform this task. Try to provide a limited list of topics short enough for a reader to grasp the full picture of the Rule of Law in a given country. Ideally, I would like a maximum of 20 events but feel free to provide less topics if the list of summaries does not cover that many events.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "We will now work with the {pillar_name} theme, which encompasses the following aspects:\n",
    "{pillar_bullets}\n",
    "\n",
    "The individual articles that we have at hand are the following:\n",
    "{summaries}\n",
    "\n",
    "All articles mentioned above have been classified to have a {impact_score} impact for the Rule of Law in {country}.\n",
    "\n",
    "Taking into account the theme and articles that I provided above, please come up with a summary of the most important topics related to this theme. Make sure to include references to the most relevant events or issues covered in the articles in each topic. Please use the theme aspects to determine how relevant is each one of the events or issues that you identified in the news articles. Use your knowledge on the specified country and focus on why these events could have a {impact_score} impact when elaborating your summary.\n",
    "\n",
    "When performing this task, please take into account the following things:\n",
    "- Please use the thematic aspects provided above to identify the most relevant issues or events.\n",
    "- Feel free to group multiple articles depending on the issue that they are covering. Avoid repeating events.\n",
    "- Limit your list to a MAXIMUM of 20 topics. Try to focus ONLY in the most important ones.\n",
    "- The description of each event or issue should be between 100 and 2000 words. Please include references to specific events narrated in the list of news articles that I provided. Please do not include references to events that were NOT MENTIONED in the list of news articles that was provided. Also, please use keywords to refer to specific articles, DO NOT use numbers for references.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting formatted prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_summaries(summaries):\n",
    "    \"\"\"\n",
    "    This function takes a list of summaries and provides a text compiling all of them but taking into account the \n",
    "    token limit for using the Gemini 1.5 Flash\n",
    "    \"\"\"\n",
    "\n",
    "    idx = 0\n",
    "    segments = [[]]\n",
    "    total_count = 0\n",
    "\n",
    "    for text in summaries:\n",
    "        text_length = len(text.split())\n",
    "\n",
    "        if total_count + text_length < 950000:      # The limit is 1.048 Million tokens, I'm leaving a marging of error\n",
    "            segments[idx].append(text)\n",
    "            total_count = total_count + text_length\n",
    "        else:\n",
    "            segments.append([])\n",
    "            idx = idx + 1\n",
    "            total_count = 0\n",
    "            segments[idx].append(text)\n",
    "            total_count = total_count + text_length\n",
    "\n",
    "    outcome = [\"- \"+\"\\n- \".join(segment) for segment in segments]\n",
    "\n",
    "    return outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing impact scores fore strings\n",
    "impact_dict = {\n",
    "    5 : \"Very Positive\",\n",
    "    4 : \"Positive\",\n",
    "    3 : \"Neutral\",\n",
    "    2 : \"Negative\",\n",
    "    1 : \"Very Negative\",\n",
    "    0 : \"Undefined\"\n",
    "}\n",
    "for p in range(0,8):\n",
    "    country_data[p][\"impact_score\"] = country_data[p].impact_score.replace(impact_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = {}\n",
    "tokens_counter = 0\n",
    "\n",
    "for p in range(1,9):\n",
    "    prompts.update(\n",
    "        {f\"Pillar {p}\" : {}}\n",
    "    )\n",
    "    \n",
    "    for impact_score in [impact for score, impact in impact_dict.items() if score != 0]:\n",
    "\n",
    "        # Subsetting data\n",
    "        pillar_data = country_data[p-1].copy()\n",
    "        data_subset = (\n",
    "            pillar_data.copy()\n",
    "            .loc[pillar_data[\"impact_score\"] == impact_score]\n",
    "        )\n",
    "\n",
    "        # Getting news summaries with URL reference\n",
    "        # data_subset[\"summary_linked\"] = data_subset[\"summary\"].str.cat(data_subset[\"link\"], sep = \"/nURL: \")\n",
    "        # article_list   = data_subset[\"summary_linked\"].to_list()\n",
    "        article_list   = data_subset[\"summary\"].to_list()\n",
    "        limited_chunks = split_summaries(article_list)      # We need to split chunks larger than 1 million tokens\n",
    "\n",
    "        # Tokens counter\n",
    "        tokens_counter = tokens_counter + sum([len(x.split()) for x in limited_chunks])\n",
    "\n",
    "        # Formatting prompts\n",
    "        formatted_prompts = [\n",
    "            prompt_template.format_map(\n",
    "                {\n",
    "                    \"pillar_name\"    : pts.pillar_names[str(p)],\n",
    "                    \"pillar_bullets\" : pts.pillar_bullets[str(p)],\n",
    "                    \"country\"        : country,\n",
    "                    \"summaries\"      : x,\n",
    "                    \"impact_score\"   : impact_score\n",
    "                }\n",
    "            )\n",
    "\n",
    "            for x in limited_chunks\n",
    "        ]\n",
    "        prompts[f\"Pillar {p}\"].update({f\"{impact_score}\" : formatted_prompts})       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pillar, score_list in prompts.items():\n",
    "    for score, np in score_list.items():\n",
    "        if len(np) > 1:\n",
    "            print(f\"Pillar: {pillar} --- {score} --- Total Prompts: {len(np)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Previewing prompts\n",
    "# pillar = 4\n",
    "# print(\n",
    "#     prompts[f\"Pillar {pillar}\"][\"Very Positive\"][0]\n",
    "#     prompts[f\"Pillar {pillar}\"][\"Positive\"][0]\n",
    "#     prompts[f\"Pillar {pillar}\"][\"Neutral\"][0]\n",
    "#     prompts[f\"Pillar {pillar}\"][\"Negative\"][0]\n",
    "#     prompts[f\"Pillar {pillar}\"][\"Very Negative\"][0]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending calls to Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "  \"temperature\": 0.25,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 64,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "safety_settings = {\n",
    "  HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "  HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "  HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "  HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_call(message, context = prompt_system, gconfig = generation_config, sconfig = safety_settings):\n",
    "    \n",
    "    model = genai.GenerativeModel(\n",
    "        model_name         = \"gemini-1.5-pro-exp-0827\",\n",
    "        generation_config  = gconfig,\n",
    "        safety_settings    = sconfig,\n",
    "        system_instruction = context\n",
    "    )\n",
    "    chat_session = model.start_chat(\n",
    "        history = []\n",
    "    )\n",
    "\n",
    "    response = chat_session.send_message(message)\n",
    "\n",
    "    return(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pillar_summaries = {}\n",
    "for pillar, sentiments in prompts.items():\n",
    "    print(pillar)\n",
    "    pillar_summaries[pillar] = {}\n",
    "    for sentiment, p in sentiments.items():\n",
    "        print(\"-------\")\n",
    "        print(sentiment)\n",
    "        response = send_call(p[0])\n",
    "        pillar_summaries[pillar][sentiment] = response\n",
    "        pause_time = (math.ceil(len(p[0].split())/32000)+1.5)*60\n",
    "        print(f\"Pause time: {pause_time}\")\n",
    "        time.sleep = pause_time\n",
    "    print(\"===================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f\"{path2SP}/EU-S Data/Automated Qualitative Checks/Data/data-summarization-1/{country.lower()}.json\", \"w\") as file:\n",
    "    json.dump(pillar_summaries, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
